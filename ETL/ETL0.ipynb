{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------- extraction and transformation -------------------\")\n",
    "import pandas as pd  \n",
    "from sqlalchemy import create_engine  \n",
    "\n",
    "# ------------------- Koneksi Database -------------------\n",
    "hostname = \"localhost\"\n",
    "port = 5432\n",
    "username = \"postgres\"\n",
    "password = \"dataEngginer\"\n",
    "source_db = \"adventureworks\"  \n",
    "staging_db = \"staggingDB\"      \n",
    "\n",
    "# Koneksi ke database source dan staging (sudah diperbaiki)\n",
    "source_engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{hostname}:{port}/{source_db}\")\n",
    "staging_engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{hostname}:{port}/{staging_db}\")\n",
    "\n",
    "# ------------------- RAW DATA ke raw_schema -------------------\n",
    "print(\"------------- inserting raw tables to raw_schema in staging -------------\")\n",
    "\n",
    "df_raw_customer = pd.read_sql(\"SELECT * FROM sales.customer\", source_engine)\n",
    "df_raw_customer.to_sql('customer', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_person = pd.read_sql(\"SELECT * FROM person.person\", source_engine)\n",
    "df_raw_person.to_sql('person', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_product = pd.read_sql(\"SELECT * FROM production.product\", source_engine)\n",
    "df_raw_product.to_sql('product', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_pc = pd.read_sql(\"SELECT * FROM production.productcategory\", source_engine)\n",
    "df_raw_pc.to_sql('productcategory', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_psc = pd.read_sql(\"SELECT * FROM production.productsubcategory\", source_engine)\n",
    "df_raw_psc.to_sql('productsubcategory', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_soh = pd.read_sql(\"SELECT * FROM sales.salesorderheader\", source_engine)\n",
    "df_raw_soh.to_sql('salesorderheader', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_sod = pd.read_sql(\"SELECT * FROM sales.salesorderdetail\", source_engine)\n",
    "df_raw_sod.to_sql('salesorderdetail', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_st = pd.read_sql(\"SELECT * FROM sales.salesterritory\", source_engine)\n",
    "df_raw_st.to_sql('salesterritory', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_sp = pd.read_sql(\"SELECT * FROM person.stateprovince\", source_engine)\n",
    "df_raw_sp.to_sql('stateprovince', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "df_raw_cr = pd.read_sql(\"SELECT * FROM person.countryregion\", source_engine)\n",
    "df_raw_cr.to_sql('countryregion', staging_engine, schema='raw_schema', if_exists='replace', index=False)\n",
    "\n",
    "print(\"Raw tables successfully inserted into raw_schema.\")\n",
    "\n",
    "# ------------------- EXTRACT + TRANSFORM -------------------\n",
    "\n",
    "# DIM_CUSTOMER\n",
    "query_customer = \"\"\"\n",
    "SELECT c.customerid,\n",
    "       pp.firstname || ' ' || COALESCE(pp.middlename || ' ', '') || pp.lastname AS customername\n",
    "FROM sales.customer c\n",
    "JOIN person.person pp ON c.personid = pp.businessentityid;\n",
    "\"\"\"\n",
    "df_customer = pd.read_sql(query_customer, source_engine)\n",
    "df_customer['customerKey'] = range(1, len(df_customer)+1)\n",
    "\n",
    "# DIM_PRODUCT\n",
    "query_product = \"\"\"\n",
    "SELECT p.productid, pc.name AS productsubcategory, p.name AS productname\n",
    "FROM production.product p\n",
    "JOIN production.productsubcategory psc ON p.productsubcategoryid = psc.productsubcategoryid\n",
    "JOIN production.productcategory pc ON psc.productcategoryid = pc.productcategoryid;\n",
    "\"\"\"\n",
    "df_product = pd.read_sql(query_product, source_engine)\n",
    "df_product['productKey'] = range(1, len(df_product)+1)\n",
    "\n",
    "# DIM_TERRITORY\n",
    "query_territory = \"\"\"\n",
    "SELECT st.territoryid, sp.name AS provincename, cr.name AS countryregion\n",
    "FROM sales.salesterritory st\n",
    "JOIN person.stateprovince sp ON st.territoryID = sp.territoryID\n",
    "JOIN person.countryregion cr ON st.countryregioncode = cr.countryregioncode;\n",
    "\"\"\"\n",
    "df_territory = pd.read_sql(query_territory, source_engine)\n",
    "df_territory['territoryKey'] = range(1, len(df_territory)+1)\n",
    "\n",
    "# FACT_SALES\n",
    "query_sales = \"\"\"\n",
    "SELECT soh.orderdate, soh.customerid, soh.territoryid, sod.productid,\n",
    "       sod.orderqty, soh.totaldue\n",
    "FROM sales.salesorderdetail sod\n",
    "JOIN sales.salesorderheader soh ON sod.salesorderid = soh.salesorderid;\n",
    "\"\"\"\n",
    "df_sales = pd.read_sql(query_sales, source_engine)\n",
    "\n",
    "# DIM_TIME\n",
    "df_time = df_sales[['orderdate']].drop_duplicates()\n",
    "df_time['year'] = pd.to_datetime(df_time['orderdate']).dt.year\n",
    "df_time['month'] = pd.to_datetime(df_time['orderdate']).dt.month\n",
    "df_time['day'] = pd.to_datetime(df_time['orderdate']).dt.day\n",
    "df_time['timeKey'] = range(1, len(df_time)+1)\n",
    "\n",
    "# Join surrogate keys ke fact_sales\n",
    "df_sales = df_sales.merge(df_customer[['customerid', 'customerKey']], on='customerid', how='left')\n",
    "df_sales = df_sales.merge(df_product[['productid', 'productKey']], on='productid', how='left')\n",
    "df_sales = df_sales.merge(df_territory[['territoryid', 'territoryKey']], on='territoryid', how='left')\n",
    "df_sales = df_sales.merge(df_time[['orderdate', 'timeKey']], on='orderdate', how='left')\n",
    "\n",
    "# Agregasi fact_sales\n",
    "df_fact = df_sales.groupby(['customerKey', 'productKey', 'territoryKey', 'timeKey']).agg(\n",
    "    totalQuantity=('orderqty', 'sum'),\n",
    "    averageAmount=('totaldue', 'mean'),\n",
    "    totalRevenue=('totaldue', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "df_fact['salesID'] = range(1, len(df_fact)+1)\n",
    "\n",
    "# ------------------- LOAD KE star_schema -------------------\n",
    "\n",
    "df_customer.to_sql('dim_customer', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "df_product.to_sql('dim_product', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "df_territory.to_sql('dim_territory', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "df_time[['timeKey', 'year', 'month', 'day']].to_sql('dim_time', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "df_fact.to_sql('fact_sales', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "\n",
    "# ------------------- DONE -------------------\n",
    "print(\"ETL selesai. Data berhasil disimpan ke staging database:\")\n",
    "print(\"- raw_schema: semua tabel sumber (sesuai LDM)\")\n",
    "print(\"- star_schema: tabel dim_customer, dim_product, dim_territory, dim_time, fact_sales\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------- Load data ke Data Warehouse -------------------\")\n",
    "import pandas as pd  \n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Koneksi database\n",
    "hostname = \"localhost\"  \n",
    "port = 5432  \n",
    "username = \"postgres\"  \n",
    "password = \"dataEngginer\"  \n",
    "dw_db = \"adventureworksDw\"  \n",
    "staging_db = \"staggingDB\"  \n",
    "\n",
    "# Membuat koneksi ke data warehouse menggunakan SQLAlchemy\n",
    "dw_engine = create_engine(f'postgresql://{username}:{password}@{hostname}:{port}/{dw_db}')\n",
    "# Membuat koneksi ke staging database menggunakan SQLAlchemy\n",
    "staging_engine = create_engine(f'postgresql://{username}:{password}@{hostname}:{port}/{staging_db}')\n",
    "\n",
    "# List tabel star schema yang akan di-load\n",
    "tables = ['dim_customer', 'dim_product', 'dim_territory', 'dim_time', 'fact_sales']\n",
    "\n",
    "def load_table(table_name):\n",
    "    try:\n",
    "        print(f\"Loading table {table_name}...\")\n",
    "        # Ambil data dari staging\n",
    "        df = pd.read_sql(f'SELECT * FROM public.{table_name}', staging_engine)\n",
    "\n",
    "        # Cek apakah tabel sudah ada di data warehouse\n",
    "        inspector = inspect(dw_engine)\n",
    "        if table_name in inspector.get_table_names():\n",
    "            # Bisa pilih strategi: replace, append, atau skip\n",
    "            # Contoh: replace supaya data update total\n",
    "            df.to_sql(table_name, dw_engine, if_exists='replace', index=False)\n",
    "            print(f\"Table {table_name} berhasil di-replace di Data Warehouse.\")\n",
    "        else:\n",
    "            df.to_sql(table_name, dw_engine, if_exists='fail', index=False)\n",
    "            print(f\"Table {table_name} berhasil di-load di Data Warehouse.\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Gagal load table {table_name}: {e}\")\n",
    "\n",
    "# Looping load semua tabel\n",
    "for table in tables:\n",
    "    load_table(table)\n",
    "\n",
    "print(\"Load ke Data Warehouse selesai.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61505b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------- incremental ETL on the phase of Load to Data Warehouse -------------------\")\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# --- Konfigurasi koneksi database ---\n",
    "hostname = \"localhost\"\n",
    "port = 5432\n",
    "username = \"postgres\"\n",
    "password = \"dataEngginer\"\n",
    "dw_db = \"adventureworksdw\"\n",
    "staging_db = \"staggingDB\"\n",
    "\n",
    "# Koneksi ke staging dan data warehouse\n",
    "staging_engine = create_engine(f'postgresql://{username}:{password}@{hostname}:{port}/{staging_db}')\n",
    "dw_engine = create_engine(f'postgresql://{username}:{password}@{hostname}:{port}/{dw_db}')\n",
    "\n",
    "# Fungsi bantu untuk load tabel dari staging ke data warehouse\n",
    "def load_table(table_name):\n",
    "    try:\n",
    "        print(f\"Loading table {table_name} ke Data Warehouse...\")\n",
    "        \n",
    "        # Ambil data dari schema stage\n",
    "        df = pd.read_sql_table(table_name, con=staging_engine, schema='stage')\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"Tidak ada data baru untuk dimuat di {table_name}.\")\n",
    "            return\n",
    "\n",
    "        # Replace data di schema adventureworksdw\n",
    "        df.to_sql(table_name, con=dw_engine, schema='public', if_exists='replace', index=False)\n",
    "        print(f\"Tabel {table_name} berhasil di-replace di Data Warehouse.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal memuat tabel {table_name} ke DW. Error: {e}\")\n",
    "\n",
    "# =====================\n",
    "# Proses Load Dimensi\n",
    "# =====================\n",
    "load_table('dim_customer')\n",
    "load_table('dim_product')\n",
    "load_table('dim_territory')\n",
    "load_table('dim_time')\n",
    "\n",
    "# =====================\n",
    "# Proses Load Fakta\n",
    "# =====================\n",
    "load_table('fact_sales')\n",
    "\n",
    "print(\"✅ Load ke Data Warehouse selesai.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ad3c4",
   "metadata": {},
   "source": [
    "OMG ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d1dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Extraction and Incremental Transformation -------------------\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.InvalidSchemaName) no schema has been selected to create in\nLINE 2:                 CREATE TABLE IF NOT EXISTS etl_control (\n                                                   ^\n\n[SQL: \n                CREATE TABLE IF NOT EXISTS etl_control (\n                    id INT PRIMARY KEY,\n                    last_orderdate DATE\n                )\n            ]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUndefinedTable\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUndefinedTable\u001b[39m: relation \"etl_control\" does not exist\nLINE 1: SELECT last_orderdate FROM etl_control WHERE id=1\n                                   ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mget_last_processed_date\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m staging_engine.connect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     result = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.fetchone()\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m result[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1630\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1631\u001b[39m     dialect=dialect,\n\u001b[32m   1632\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1636\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1637\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1638\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2351\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mProgrammingError\u001b[39m: (psycopg2.errors.UndefinedTable) relation \"etl_control\" does not exist\nLINE 1: SELECT last_orderdate FROM etl_control WHERE id=1\n                                   ^\n\n[SQL: SELECT last_orderdate FROM etl_control WHERE id=1]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mInvalidSchemaName\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mInvalidSchemaName\u001b[39m: no schema has been selected to create in\nLINE 2:                 CREATE TABLE IF NOT EXISTS etl_control (\n                                                   ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m         conn.commit()\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# ------------------- Ambil last processed date -------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m last_date = \u001b[43mget_last_processed_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLast processed orderdate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# ------------------- Extract incremental data -------------------\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mget_last_processed_date\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Jika tabel etl_control belum ada, buat dan insert row default\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m staging_engine.connect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m         \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[33;43m            CREATE TABLE IF NOT EXISTS etl_control (\u001b[39;49m\n\u001b[32m     36\u001b[39m \u001b[33;43m                id INT PRIMARY KEY,\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[33;43m                last_orderdate DATE\u001b[39;49m\n\u001b[32m     38\u001b[39m \u001b[33;43m            )\u001b[39;49m\n\u001b[32m     39\u001b[39m \u001b[33;43m        \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m         conn.execute(text(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[33m            INSERT INTO etl_control (id, last_orderdate) VALUES (1, NULL)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[33m            ON CONFLICT (id) DO NOTHING\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m))\n\u001b[32m     44\u001b[39m         conn.commit()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    522\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1626\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1627\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1628\u001b[39m )\n\u001b[32m   1630\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1631\u001b[39m     dialect=dialect,\n\u001b[32m   1632\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1636\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1637\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1638\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1652\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1653\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1657\u001b[39m         ret,\n\u001b[32m   1658\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1980\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2351\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2354\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1962\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1969\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1970\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1971\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1975\u001b[39m         context.executemany,\n\u001b[32m   1976\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mProgrammingError\u001b[39m: (psycopg2.errors.InvalidSchemaName) no schema has been selected to create in\nLINE 2:                 CREATE TABLE IF NOT EXISTS etl_control (\n                                                   ^\n\n[SQL: \n                CREATE TABLE IF NOT EXISTS etl_control (\n                    id INT PRIMARY KEY,\n                    last_orderdate DATE\n                )\n            ]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "print(\"------------------- Extraction and Incremental Transformation -------------------\")\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# ------------------- Koneksi Database -------------------\n",
    "hostname = \"localhost\"\n",
    "port = 5432\n",
    "username = \"postgres\"\n",
    "password = \"dataEngginer\"\n",
    "source_db = \"adventureworks\"\n",
    "staging_db = \"staggingDB\"\n",
    "dw_db = \"adventureworksDw\"\n",
    "\n",
    "# Engine koneksi\n",
    "source_engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{hostname}:{port}/{source_db}\")\n",
    "staging_engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{hostname}:{port}/{staging_db}\")\n",
    "dw_engine = create_engine(f\"postgresql://{username}:{password}@{hostname}:{port}/{dw_db}\")\n",
    "\n",
    "# ------------------- Fungsi kontrol last processed date -------------------\n",
    "def get_last_processed_date():\n",
    "    try:\n",
    "        query = \"SELECT last_orderdate FROM etl_control WHERE id=1\"\n",
    "        with staging_engine.connect() as conn:\n",
    "            result = conn.execute(text(query)).fetchone()\n",
    "            if result and result[0]:\n",
    "                return result[0]\n",
    "            else:\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        # Jika tabel etl_control belum ada, buat dan insert row default\n",
    "        with staging_engine.connect() as conn:\n",
    "            conn.execute(text(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS etl_control (\n",
    "                    id INT PRIMARY KEY,\n",
    "                    last_orderdate DATE\n",
    "                )\n",
    "            \"\"\"))\n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO etl_control (id, last_orderdate) VALUES (1, NULL)\n",
    "                ON CONFLICT (id) DO NOTHING\n",
    "            \"\"\"))\n",
    "            conn.commit()\n",
    "        return None\n",
    "\n",
    "def update_last_processed_date(new_date):\n",
    "    with staging_engine.connect() as conn:\n",
    "        conn.execute(\n",
    "            text(\"UPDATE etl_control SET last_orderdate = :new_date WHERE id=1\"),\n",
    "            {\"new_date\": new_date}\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "# ------------------- Ambil last processed date -------------------\n",
    "last_date = get_last_processed_date()\n",
    "print(f\"Last processed orderdate: {last_date}\")\n",
    "\n",
    "# ------------------- Extract incremental data -------------------\n",
    "if last_date is None:\n",
    "    # Ambil semua data\n",
    "    query_sales = \"\"\"\n",
    "    SELECT soh.orderdate, soh.customerid, soh.territoryid, sod.productid,\n",
    "           sod.orderqty, soh.totaldue\n",
    "    FROM sales.salesorderdetail sod\n",
    "    JOIN sales.salesorderheader soh ON sod.salesorderid = soh.salesorderid;\n",
    "    \"\"\"\n",
    "else:\n",
    "    # Ambil data baru yang orderdate > last_date\n",
    "    query_sales = f\"\"\"\n",
    "    SELECT soh.orderdate, soh.customerid, soh.territoryid, sod.productid,\n",
    "           sod.orderqty, soh.totaldue\n",
    "    FROM sales.salesorderdetail sod\n",
    "    JOIN sales.salesorderheader soh ON sod.salesorderid = soh.salesorderid\n",
    "    WHERE soh.orderdate > '{last_date}';\n",
    "    \"\"\"\n",
    "\n",
    "df_sales = pd.read_sql(query_sales, source_engine)\n",
    "if df_sales.empty:\n",
    "    print(\"Tidak ada data baru untuk diproses.\")\n",
    "else:\n",
    "    print(f\"Data baru ditemukan: {len(df_sales)} baris.\")\n",
    "\n",
    "    # ------------------- Transform -------------------\n",
    "\n",
    "    # Dim Customer\n",
    "    query_customer = \"\"\"\n",
    "    SELECT c.customerid,\n",
    "           pp.firstname || ' ' || COALESCE(pp.middlename || ' ', '') || pp.lastname AS customername\n",
    "    FROM sales.customer c\n",
    "    JOIN person.person pp ON c.personid = pp.businessentityid;\n",
    "    \"\"\"\n",
    "    df_customer = pd.read_sql(query_customer, source_engine)\n",
    "    df_customer['customerKey'] = range(1, len(df_customer)+1)\n",
    "\n",
    "    # Dim Product\n",
    "    query_product = \"\"\"\n",
    "    SELECT p.productid, pc.name AS productsubcategory, p.name AS productname\n",
    "    FROM production.product p\n",
    "    JOIN production.productsubcategory psc ON p.productsubcategoryid = psc.productsubcategoryid\n",
    "    JOIN production.productcategory pc ON psc.productcategoryid = pc.productcategoryid;\n",
    "    \"\"\"\n",
    "    df_product = pd.read_sql(query_product, source_engine)\n",
    "    df_product['productKey'] = range(1, len(df_product)+1)\n",
    "\n",
    "    # Dim Territory\n",
    "    query_territory = \"\"\"\n",
    "    SELECT st.territoryid, sp.name AS provincename, cr.name AS countryregion\n",
    "    FROM sales.salesterritory st\n",
    "    JOIN person.stateprovince sp ON st.territoryID = sp.territoryID\n",
    "    JOIN person.countryregion cr ON st.countryregioncode = cr.countryregioncode;\n",
    "    \"\"\"\n",
    "    df_territory = pd.read_sql(query_territory, source_engine)\n",
    "    df_territory['territoryKey'] = range(1, len(df_territory)+1)\n",
    "\n",
    "    # Dim Time\n",
    "    df_time = df_sales[['orderdate']].drop_duplicates()\n",
    "    df_time['year'] = pd.to_datetime(df_time['orderdate']).dt.year\n",
    "    df_time['month'] = pd.to_datetime(df_time['orderdate']).dt.month\n",
    "    df_time['day'] = pd.to_datetime(df_time['orderdate']).dt.day\n",
    "    df_time['timeKey'] = range(1, len(df_time)+1)\n",
    "\n",
    "    # Join surrogate keys ke fact_sales\n",
    "    df_sales = df_sales.merge(df_customer[['customerid', 'customerKey']], on='customerid', how='left')\n",
    "    df_sales = df_sales.merge(df_product[['productid', 'productKey']], on='productid', how='left')\n",
    "    df_sales = df_sales.merge(df_territory[['territoryid', 'territoryKey']], on='territoryid', how='left')\n",
    "    df_sales = df_sales.merge(df_time[['orderdate', 'timeKey']], on='orderdate', how='left')\n",
    "\n",
    "    # Agregasi fact_sales\n",
    "    df_fact = df_sales.groupby(['customerKey', 'productKey', 'territoryKey', 'timeKey']).agg(\n",
    "        totalQuantity=('orderqty', 'sum'),\n",
    "        averageAmount=('totaldue', 'mean'),\n",
    "        totalRevenue=('totaldue', 'sum')\n",
    "    ).reset_index()\n",
    "    df_fact['salesID'] = range(1, len(df_fact)+1)\n",
    "\n",
    "    # ------------------- Load ke staging -------------------\n",
    "    df_customer.to_sql('dim_customer', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "    df_product.to_sql('dim_product', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "    df_territory.to_sql('dim_territory', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "    df_time[['timeKey', 'year', 'month', 'day']].to_sql('dim_time', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "    df_fact.to_sql('fact_sales', staging_engine, schema='star_schema', if_exists='replace', index=False)\n",
    "\n",
    "    print(\"Data berhasil ditransformasi dan dimuat ke staging.\")\n",
    "\n",
    "    # ------------------- Load ke Data Warehouse -------------------\n",
    "    tables = ['dim_customer', 'dim_product', 'dim_territory', 'dim_time', 'fact_sales']\n",
    "\n",
    "    def load_table(table_name):\n",
    "        try:\n",
    "            print(f\"Loading table {table_name} ke Data Warehouse...\")\n",
    "            df = pd.read_sql(f'SELECT * FROM star_schema.{table_name}', staging_engine)\n",
    "\n",
    "            inspector = inspect(dw_engine)\n",
    "            if table_name in inspector.get_table_names():\n",
    "                df.to_sql(table_name, dw_engine, if_exists='replace', index=False)\n",
    "                print(f\"Tabel {table_name} berhasil di-replace di Data Warehouse.\")\n",
    "            else:\n",
    "                df.to_sql(table_name, dw_engine, if_exists='fail', index=False)\n",
    "                print(f\"Tabel {table_name} berhasil di-load di Data Warehouse.\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"Gagal load tabel {table_name}: {e}\")\n",
    "\n",
    "    for table in tables:\n",
    "        load_table(table)\n",
    "\n",
    "    print(\"Load ke Data Warehouse selesai.\")\n",
    "\n",
    "    # ------------------- Update last processed date -------------------\n",
    "    max_date = df_sales['orderdate'].max()\n",
    "    update_last_processed_date(max_date)\n",
    "    print(f\"Last processed orderdate di-update ke: {max_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3528af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------- Koneksi Database -------------------\n",
    "hostname = \"localhost\"\n",
    "port = 5432\n",
    "username = \"postgres\"\n",
    "password = \"dataEngginer\"\n",
    "source_db = \"adventureworks\"\n",
    "staging_db = \"staggingDB\"\n",
    "\n",
    "source_engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{hostname}:{port}/{source_db}\")\n",
    "staging_engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{hostname}:{port}/{staging_db}\")\n",
    "\n",
    "# ------------------- PARAMETER BATAS WAKTU -------------------\n",
    "# Ambil waktu terakhir dari staging (misal dari fact_sales, kolom orderdate)\n",
    "try:\n",
    "    last_time_query = \"SELECT MAX(orderdate) FROM star_schema.fact_sales;\"\n",
    "    last_order_date = pd.read_sql(last_time_query, staging_engine).iloc[0, 0]\n",
    "    if pd.isna(last_order_date):\n",
    "        last_order_date = datetime(1900, 1, 1)  # jika kosong\n",
    "except:\n",
    "    last_order_date = datetime(1900, 1, 1)\n",
    "\n",
    "print(f\"Last order date from staging: {last_order_date}\")\n",
    "\n",
    "# ------------------- EXTRACT & TRANSFORM INCREMENTAL -------------------\n",
    "query_sales = f\"\"\"\n",
    "SELECT soh.orderdate, soh.customerid, soh.territoryid, sod.productid,\n",
    "       sod.orderqty, soh.totaldue\n",
    "FROM sales.salesorderdetail sod\n",
    "JOIN sales.salesorderheader soh ON sod.salesorderid = soh.salesorderid\n",
    "WHERE soh.orderdate > '{last_order_date}';\n",
    "\"\"\"\n",
    "df_sales = pd.read_sql(query_sales, source_engine)\n",
    "\n",
    "if df_sales.empty:\n",
    "    print(\"Tidak ada data baru untuk diproses.\")\n",
    "    exit()\n",
    "\n",
    "# Dimensi\n",
    "df_customer = pd.read_sql(\"SELECT customerid, personid FROM sales.customer\", source_engine)\n",
    "df_person = pd.read_sql(\"SELECT businessentityid, firstname, middlename, lastname FROM person.person\", source_engine)\n",
    "df_customer = df_customer.merge(df_person, left_on='personid', right_on='businessentityid', how='left')\n",
    "df_customer['customername'] = df_customer['firstname'] + ' ' + df_customer['middlename'].fillna('') + ' ' + df_customer['lastname']\n",
    "df_customer = df_customer[['customerid', 'customername']].drop_duplicates()\n",
    "\n",
    "df_product = pd.read_sql(\"\"\"\n",
    "SELECT p.productid, pc.name AS productsubcategory, p.name AS productname\n",
    "FROM production.product p\n",
    "JOIN production.productsubcategory psc ON p.productsubcategoryid = psc.productsubcategoryid\n",
    "JOIN production.productcategory pc ON psc.productcategoryid = pc.productcategoryid\n",
    "\"\"\", source_engine)\n",
    "\n",
    "df_territory = pd.read_sql(\"\"\"\n",
    "SELECT st.territoryid, sp.name AS provincename, cr.name AS countryregion\n",
    "FROM sales.salesterritory st\n",
    "JOIN person.stateprovince sp ON st.territoryID = sp.territoryID\n",
    "JOIN person.countryregion cr ON st.countryregioncode = cr.countryregioncode;\n",
    "\"\"\", source_engine)\n",
    "\n",
    "# Time dimension\n",
    "df_time = df_sales[['orderdate']].drop_duplicates()\n",
    "df_time['year'] = pd.to_datetime(df_time['orderdate']).dt.year\n",
    "df_time['month'] = pd.to_datetime(df_time['orderdate']).dt.month\n",
    "df_time['day'] = pd.to_datetime(df_time['orderdate']).dt.day\n",
    "\n",
    "# Simpan ke file sementara / staging\n",
    "df_customer.to_csv(\"staging_dim_customer.csv\", index=False)\n",
    "df_product.to_csv(\"staging_dim_product.csv\", index=False)\n",
    "df_territory.to_csv(\"staging_dim_territory.csv\", index=False)\n",
    "df_time.to_csv(\"staging_dim_time.csv\", index=False)\n",
    "df_sales.to_csv(\"staging_fact_sales.csv\", index=False)\n",
    "\n",
    "print(\"Incremental extract & transform selesai. File CSV siap untuk load.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc495d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data baru dim_product sejak {last_etl_time}: {len(df_product)} rows\")\n",
    "print(df_product.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
